{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback, CSVLogger, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_lstm(path='./', lr = 0.01, batch_size = 128, epochs = 50, units = 256):\n",
    "    # path: target profile dir path\n",
    "    # create required dirs\n",
    "    model_path = path+'/lstm_models/'\n",
    "    trainable_text = './t8.shakespeare.txt'\n",
    "    num_lines = 1000\n",
    "\n",
    "    for p in [model_path]:\n",
    "        if not os.path.isdir(p):\n",
    "            os.mkdir(p)\n",
    "\n",
    "    csv_logger = CSVLogger(path+'/')\n",
    "    \n",
    "    # load text\n",
    "\n",
    "    with open(trainable_text) as f:\n",
    "        # head = [next(f) for x in range(num_lines)]\n",
    "        head = f.read().split('\\n')[11000:40000]\n",
    "    \n",
    "    text = ' '.join(head).split(' ')\n",
    "    print('\\033[96m[+] Trainable corpus length:\\033[0m', len(text))\n",
    "\n",
    "\n",
    "    chars = sorted(list(set(text)))\n",
    "    print('\\033[96m[+] Unique Chars:\\033[0m', len(chars))     \n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    # pickle char_indices and indices_char for futire use\n",
    "    pickle.dump(char_indices, open(path+'char_indices','wb'))\n",
    "    pickle.dump(indices_char, open(path+'indices_char','wb'))\n",
    "\n",
    "    # generate dataset of semi-redundant sequences of maxlen characters\n",
    "    maxlen = 50\n",
    "    step = 3\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "\n",
    "    # one hot encoding \n",
    "    x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "    # build model\n",
    "    print('\\033[96m[+] Building LSTM model\\033[0m')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dense(len(chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    checkpointer = ModelCheckpoint(filepath=model_path+'/weights_{epoch:02d}_{loss:.4f}.hdf5')\n",
    "    csv_logger = CSVLogger(path+'/keras_lstm_training.log')\n",
    "    model.fit( x, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "    # on_epoch_end(19, 'garbge')\n",
    "    print('\\033[96m[+] Saved trained models on every iteration at {}.\\033[0m'.format(model_path))\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm(path='./', lr = 0.01, batch_size = 128, epochs = 2, units = 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
